{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uyCiLbXbsMiq",
    "outputId": "7145b015-6fa5-4de8-da30-8d9d4662ebb8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (10.0, 8.0)  # set default size of plots\n",
    "plt.rcParams[\"image.interpolation\"] = \"nearest\"\n",
    "plt.rcParams[\"image.cmap\"] = \"gray\"\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m l \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m      2\u001b[0m l\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43ml\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "l = list()\n",
    "l.append(1)\n",
    "l[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "7dHogdxRsMis"
   },
   "outputs": [],
   "source": [
    "# Some suggestions of our libraries that might be helpful for this project\n",
    "from collections import Counter  # an even easier way to count\n",
    "from multiprocessing import Pool  # for multiprocessing\n",
    "from tqdm import tqdm  # fancy progress bars\n",
    "\n",
    "# Load other libraries here.\n",
    "# Keep it minimal! We should be easily able to reproduce your code.\n",
    "\n",
    "# We preload pytorch as an example\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numpy import argmax\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJWkh3GUsMit"
   },
   "source": [
    "# Setup\n",
    "\n",
    "  * Download the datasets: [train](https://nextcloud.mpi-klsb.mpg.de/index.php/s/pJrRGzm2So2PMZm) (128M) and [test](https://nextcloud.mpi-klsb.mpg.de/index.php/s/zN3yeWzQB3i5WqE) (92M)\n",
    "  * Unpack them under `./data/train` and `./data/test`\n",
    "  * Hint: you can execute shell scripts from notebooks using the `!` prefix, e.g., `! wget <url>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Noj1Wo_gqsIe"
   },
   "outputs": [],
   "source": [
    "!wget -O train.tar.gz https://nextcloud.mpi-klsb.mpg.de/index.php/s/pJrRGzm2So2PMZm/download\n",
    "!mkdir -p \"./data/train\"\n",
    "!tar -c \"./data/train\" -zxvf train.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q7G5vlnLqsIe"
   },
   "outputs": [],
   "source": [
    "!wget -O test.tar.gz https://nextcloud.mpi-klsb.mpg.de/index.php/s/zN3yeWzQB3i5WqE/download\n",
    "!mkdir -p \"./data/test\"\n",
    "!tar -c \"./data/test\" -zxvf test.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wlhs4w44sMit",
    "outputId": "d58e6463-3fbf-402d-c625-e0c228243d0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# train examples (Should be 13682) :    13682\n",
      "# test  examples (Should be 10000) :    10000\n"
     ]
    }
   ],
   "source": [
    "# Check that you are prepared with the data\n",
    "! printf '# train examples (Should be 13682) : '; ls data/train | wc -l\n",
    "! printf '# test  examples (Should be 10000) : '; ls data/test | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zh1-JHNIsMiv"
   },
   "source": [
    "Now that you're set, we will briefly look at the data.\n",
    "Each file encodes the behavior report of a program (potentially a malware), using an encoding scheme called \"The Malware Instruction Set\" (MIST for short).\n",
    "At this point, read-up Sec. 2 of the [MIST](http://www.mlsec.org/malheur/docs/mist-tr.pdf) documentation.\n",
    "\n",
    "find each file named as `filename.<malwarename>`:\n",
    "```\n",
    "» ls data/train | head\n",
    "00005ecc06ae3e489042e979717bb1455f17ac9d.NothingFound\n",
    "0008e3d188483aeae0de62d8d3a1479bd63ed8c9.Basun\n",
    "000d2eea77ee037b7ef99586eb2f1433991baca9.Patched\n",
    "000d996fa8f3c83c1c5568687bb3883a543ec874.Basun\n",
    "0010f78d3ffee61101068a0722e09a98959a5f2c.Basun\n",
    "0013cd0a8febd88bfc4333e20486bd1a9816fcbf.Basun\n",
    "0014aca72eb88a7f20fce5a4e000c1f7fff4958a.Texel\n",
    "001ffc75f24a0ae63a7033a01b8152ba371f6154.Texel\n",
    "0022d6ba67d556b931e3ab26abcd7490393703c4.Basun\n",
    "0028c307a125cf0fdc97d7a1ffce118c6e560a70.Swizzor\n",
    "...\n",
    "```\n",
    "and within each file, a sequence of individual systems calls monitored duing the run-time of the binary - a malware named 'Basun' in the case:\n",
    "```\n",
    "» head data/train/000d996fa8f3c83c1c5568687bb3883a543ec874.Basun\n",
    "# process 000006c8 0000066a 022c82f4 00000000 thread 0001 #\n",
    "02 01 | 000006c8 0000066a 00015000\n",
    "02 02 | 00006b2c 047c8042 000b9000\n",
    "02 02 | 00006b2c 047c8042 00108000\n",
    "02 02 | 00006b2c 047c8042 00153000\n",
    "02 02 | 00006b2c 047c8042 00091000\n",
    "02 02 | 00006b2c 047c8042 00049000\n",
    "02 02 | 00006b2c 047c8042 000aa000\n",
    "02 02 | 00006b2c 047c8042 00092000\n",
    "02 02 | 00006b2c 047c8042 00011000\n",
    "...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8xloR8dsMiv"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXnyDAdbsMiw"
   },
   "source": [
    "#  Vectorize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ia-xFIQtsMiw"
   },
   "source": [
    "##  Load Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g79070AeSH9x"
   },
   "source": [
    "Define global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2puJqH_SqsIg"
   },
   "outputs": [],
   "source": [
    "flag = 0#set flag = 0 for generating only train and validatation data and flag =1 for generating only test(as it consumes more ram to generate all datasets simultaniously)\n",
    "MAX_VOCAB_SIZE = 10000#maximum number of tokens to be considered\n",
    "gram = \"bigram\"  # unigram or bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jeNOI2PSfte"
   },
   "source": [
    "Define functions to load raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ZScY-C2IsMiw"
   },
   "outputs": [],
   "source": [
    "def load_content(filepath):\n",
    "    \"\"\"Given a filepath, returns (content, classname), where content = [list of lines in file]\"\"\"\n",
    "    #\n",
    "    #\n",
    "    # ------- Your Code -------\n",
    "    #\n",
    "    #\n",
    "    lines = []\n",
    "    # reading each line from original file\n",
    "    with open(filepath, \"r\") as f:\n",
    "        for line in f:\n",
    "            # reading all lines that do not\n",
    "            # begin with \"# process\"\"\n",
    "            if not (line.startswith(\"# process\")):\n",
    "                lines.append(line[:-1])\n",
    "    label = os.path.splitext(filepath)[1]\n",
    "    return lines, label[1:]\n",
    "\n",
    "\n",
    "def load_data(data_path, nworkers=10):\n",
    "    \"\"\"Returns each data sample as a tuple (x, y), x = sequence of strings (i.e., syscalls), y = malware program class\"\"\"\n",
    "\n",
    "    raw_data_samples = []\n",
    "    #\n",
    "    #\n",
    "    # ------- Your Code -------\n",
    "    #\n",
    "    #\n",
    "    files = [f for f in glob.glob(data_path + \"*.*\", recursive=True)]\n",
    "    with tqdm(total=len(files)) as pbar:\n",
    "        for file in files:\n",
    "            raw_data_samples.append((load_content(file)))\n",
    "            pbar.update(1)\n",
    "    return raw_data_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7BSUdq_-sMiw",
    "outputId": "14534140-0b9c-4d5f-eb23-df6e019a5883",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13682/13682 [02:00<00:00, 113.43it/s]\n"
     ]
    }
   ],
   "source": [
    "if flag == 0:\n",
    "    train_raw_samples = load_data(\"data/train/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xf_wr63R0FmQ"
   },
   "source": [
    "Load raw data and split train and validation datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "GG6tcSNJsMiw",
    "outputId": "0f9f475a-4000-4430-8fbe-800a5d9a2653"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> # Train samples =  9166\n"
     ]
    }
   ],
   "source": [
    "project_mode = \"trainval\"  # trainval, traintest, debug\n",
    "np.random.seed(123)  # To perform the same split across multiple runs\n",
    "\n",
    "if project_mode == \"trainval\":\n",
    "    if flag == 0:\n",
    "        (\n",
    "            train_raw_samples,\n",
    "            val_raw_samples,\n",
    "            train_raw_samples_label,\n",
    "            val_raw_samples_label,\n",
    "        ) = train_test_split(\n",
    "            [i[0] for i in train_raw_samples],\n",
    "            [i[1] for i in train_raw_samples],\n",
    "            test_size=0.33,\n",
    "            shuffle=True,\n",
    "        )\n",
    "    if flag != 0:\n",
    "        test_raw_samples = load_data(\"data/test/\")\n",
    "        test_raw_samples_label = [i[1] for i in test_raw_samples]\n",
    "        test_raw_samples = [i[0] for i in test_raw_samples]\n",
    "elif project_mode == \"debug\":\n",
    "    # Optional, use a small subset of the training and validation data for fast debugging\n",
    "    train_raw_samples_label = [i[1] for i in train_raw_samples]\n",
    "    train_raw_samples = [i[0] for i in train_raw_samples]\n",
    "\n",
    "    train_raw_samples = train_raw_samples[:1000]\n",
    "    train_raw_samples_label = train_raw_samples_label[:1000]\n",
    "else:\n",
    "    raise ValueError(\"Unrecognized mode\")\n",
    "if flag == 0:\n",
    "    print(\"=> # Train samples = \", len(train_raw_samples))\n",
    "if flag != 0:\n",
    "    print(\"=> # Test  samples = \", len(test_raw_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjiNiOVHsMiy"
   },
   "source": [
    "##  Vectorize: Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "DAtmzL6PsMiy"
   },
   "outputs": [],
   "source": [
    "def get_key_idx_map(counter, vocab_size, ukn_token=\"_unk_\"):\n",
    "    # counter is a mapping: token -> count\n",
    "    # build vectorizer using vocab_size most common elements\n",
    "    key_to_idx, idx_to_key = dict(), dict()\n",
    "    counter = counter.most_common()[:vocab_size]\n",
    "    key_to_idx = key_to_idx_helper(key_to_idx, counter, ukn_token)\n",
    "    idx_to_key = idx_to_key_helper(idx_to_key, counter)\n",
    "    return key_to_idx, idx_to_key\n",
    "\n",
    "\n",
    "def key_to_idx_helper(key_to_idx, counter, ukn_token):\n",
    "    for index, key in enumerate(counter):\n",
    "        key_to_idx[key[0]] = index\n",
    "    key_to_idx[ukn_token] = index + 1\n",
    "    return key_to_idx\n",
    "\n",
    "\n",
    "def idx_to_key_helper(idx_to_key, counter):\n",
    "    for index, key in enumerate(counter):\n",
    "        idx_to_key[index] = key[0]\n",
    "    return idx_to_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PopAWcFK1Ec9"
   },
   "source": [
    "Unigrams or bigrams are extracted from raw samples and stored according to the vocabulary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSMEAcgvsMiy",
    "outputId": "2686b17f-c76f-4e15-f659-b64d16958067"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n"
     ]
    }
   ],
   "source": [
    "vobab = []\n",
    "\n",
    "out_path = \"application_vocab_{}.pkl\".format(MAX_VOCAB_SIZE)\n",
    "if flag == 0:\n",
    "    for f in train_raw_samples:\n",
    "        for i in f:\n",
    "            if gram == \"unigram\":\n",
    "                vobab.append(i.split(\"|\")[0])  # unigram\n",
    "            else:  # bigram\n",
    "                if len(i.split(\"|\")[1].split(\" \")) >= 2:\n",
    "                    vobab.append(i.split(\"|\")[0] + i.split(\"|\")[1].split(\" \")[1])\n",
    "                else:\n",
    "                    vobab.append(i.split(\"|\")[0])  # unigram\n",
    "    token_counter = Counter(vobab)\n",
    "    print(len(token_counter))\n",
    "    token_to_idx, idx_to_token = get_key_idx_map(token_counter, MAX_VOCAB_SIZE)\n",
    "    # Save vocab to file\n",
    "\n",
    "    with open(out_path, \"wb\") as wf:\n",
    "        dct = {\"token_to_idx\": token_to_idx, \"idx_to_token\": idx_to_token}\n",
    "        pickle.dump(dct, wf)\n",
    "if flag != 0:\n",
    "    with open(out_path, \"rb\") as wf:\n",
    "        dct = pickle.load(wf)\n",
    "        token_to_idx, idx_to_token = dct[\"token_to_idx\"], dct[\"idx_to_token\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUefzVjFsMiy"
   },
   "source": [
    "##  Vectorize Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "CD5IqJmXsMiz"
   },
   "outputs": [],
   "source": [
    "def vectorize_raw_samples(gram, raw_samples, MAX_VOCAB_SIZE, nworkers=10):\n",
    "    vectorized_samples = []\n",
    "    #\n",
    "    #\n",
    "    # ------- Your Code -------\n",
    "    #\n",
    "    #\n",
    "    for file, f in enumerate(raw_samples):\n",
    "        a = [0] * (MAX_VOCAB_SIZE + 1)\n",
    "        for string, i in enumerate(f):\n",
    "            if gram == \"unigram\":\n",
    "                if i.split(\"|\")[0] in token_to_idx:  # unigram\n",
    "                    a[token_to_idx[i.split(\"|\")[0]]] += 1\n",
    "                else:\n",
    "                    a[token_to_idx[\"_unk_\"]] += 1\n",
    "            else:\n",
    "                if len(i.split(\"|\")[1].split(\" \")) >= 2:\n",
    "                    if (\n",
    "                        i.split(\"|\")[0] + i.split(\"|\")[1].split(\" \")[1] in token_to_idx\n",
    "                    ):  # bigram\n",
    "                        a[\n",
    "                            token_to_idx[\n",
    "                                i.split(\"|\")[0] + i.split(\"|\")[1].split(\" \")[1]\n",
    "                            ]\n",
    "                        ] += 1\n",
    "                elif i.split(\"|\")[0] in token_to_idx:\n",
    "                    a[token_to_idx[i.split(\"|\")[0]]] += 1\n",
    "                else:\n",
    "                    a[token_to_idx[\"_unk_\"]] += 1\n",
    "        vectorized_samples.append(a)\n",
    "    return vectorized_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_Nzl72g2vJl"
   },
   "source": [
    "Vectorizing raw samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BtS10ASbsMi0",
    "outputId": "e28b4960-6d52-4fe5-de21-95ee13bceb91",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Processing: Train\n",
      "\n",
      "=> Processing: Val\n"
     ]
    }
   ],
   "source": [
    "if flag == 0:\n",
    "    print(\"=> Processing: Train\")\n",
    "    train_data = vectorize_raw_samples(gram, train_raw_samples, MAX_VOCAB_SIZE)\n",
    "    train_raw_samples.clear()\n",
    "    print()\n",
    "    print(\"=> Processing: Val\")\n",
    "    val_data = vectorize_raw_samples(gram, val_raw_samples, MAX_VOCAB_SIZE)\n",
    "    val_raw_samples.clear()\n",
    "if flag != 0:\n",
    "    print(\"=> Processing: Test\")\n",
    "    test_data = vectorize_raw_samples(gram, test_raw_samples, MAX_VOCAB_SIZE)\n",
    "    test_raw_samples.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQ9CgxD63eyn"
   },
   "source": [
    "Transform malware classes to numerical labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w50gjS5HqsIi"
   },
   "outputs": [],
   "source": [
    "def lab_generator(label):\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(label)\n",
    "    return integer_encoded\n",
    "\n",
    "\n",
    "if flag == 0:\n",
    "    trainset = TensorDataset(\n",
    "        torch.FloatTensor(train_data),\n",
    "        torch.FloatTensor(lab_generator(train_raw_samples_label)),\n",
    "    )\n",
    "\n",
    "    valset = TensorDataset(\n",
    "        torch.FloatTensor(val_data),\n",
    "        torch.FloatTensor(lab_generator(val_raw_samples_label)),\n",
    "    )\n",
    "    torch.save(trainset, gram + \"_train\" + str(MAX_VOCAB_SIZE) + \".pt\")\n",
    "    torch.save(valset, gram + \"_val\" + str(MAX_VOCAB_SIZE) + \".pt\")\n",
    "\n",
    "if flag != 0:\n",
    "    testset = TensorDataset(\n",
    "        torch.FloatTensor(test_data),\n",
    "        torch.FloatTensor(lab_generator(test_raw_samples_label)),\n",
    "    )\n",
    "    torch.save(testset, gram + \"_test\" + str(MAX_VOCAB_SIZE) + \".pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_l0tLsEVsMi0"
   },
   "source": [
    "#  Train Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UInY1YzksMi0"
   },
   "source": [
    "##  Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "VnSv0J75sMi0"
   },
   "outputs": [],
   "source": [
    "# Feel free to edit anything in this block\n",
    "\n",
    "\n",
    "def evaluate_preds(y_gt, y_pred):\n",
    "    pass\n",
    "\n",
    "\n",
    "def another_helper(question):\n",
    "    return 42\n",
    "\n",
    "\n",
    "def save_model(model, out_path):\n",
    "    pass\n",
    "\n",
    "\n",
    "def save_data(eval_data, out_path):\n",
    "    with open(out_path, \"wb\") as wf:\n",
    "        pickle.dump(eval_data, out_path)\n",
    "\n",
    "#Weight Initialization function:\n",
    "def weights_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        m.weight.data.normal_(0.0, 1e-3)\n",
    "        m.bias.data.fill_(0.0)\n",
    "\n",
    "# Learning rate update function:\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "\n",
    "# Function to plot confusion matrix:\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhbVzVLDsMi1"
   },
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrUKCNRgsMi1"
   },
   "source": [
    "We create a tree-layer Neural network to perform the multiclass classification task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ILB2fBRWsMi1"
   },
   "outputs": [],
   "source": [
    "# Feel free to edit anything in this block\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Net, self).__init__()\n",
    "        # Linear function\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim[0])\n",
    "\n",
    "        # Non-linearity\n",
    "        self.sigmoid1 = nn.Sigmoid()\n",
    "        \n",
    "        # Linear function (readout)\n",
    "        self.fc2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n",
    "\n",
    "        # Non-linearity\n",
    "        self.sigmoid2 = nn.Sigmoid()\n",
    "\n",
    "        self.fc3 = nn.Linear(hidden_dim[1], output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Linear function  # LINEAR\n",
    "        out = self.fc1(x)\n",
    "\n",
    "        # Non-linearity  # NON-LINEAR\n",
    "        out = self.sigmoid1(out)\n",
    "\n",
    "        # Linear function (readout)  # LINEAR\n",
    "        out = self.fc2(out)\n",
    "        # Non-linearity  # NON-LINEAR\n",
    "        out = self.sigmoid2(out)\n",
    "\n",
    "        # Linear function (readout)  # LINEAR\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QO1yPx7YsMi1"
   },
   "source": [
    "##  Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BmK69tYOqsIj"
   },
   "outputs": [],
   "source": [
    "log_interval = 10\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "rndm_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "0k0jLX5ksMi1"
   },
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 100\n",
    "num_epochs = 50\n",
    "reg = 0.001\n",
    "input_dim = 10001#input dimensions =10000 tokens + 1 unknown token\n",
    "hidden_dim = [1000, 800]\n",
    "output_dim = 10\n",
    "\n",
    "model = Net(input_dim, hidden_dim, output_dim)\n",
    "model.apply(weights_init)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 2e-3\n",
    "learning_rate_decay = 0.95\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtpgVAO1sMi2"
   },
   "source": [
    "##  Train your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-Fp11rXQzaH"
   },
   "source": [
    "Loading n-grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RjzGz8b5qsIk",
    "outputId": "8f54ea1d-8df3-44bc-91f2-5bf745004849"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "traindata = torch.load(\"bigram _train10000.pt\")\n",
    "validate = torch.load(\"bigram _val10000.pt\")\n",
    "test = torch.load(\"bigram _test10000.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usLM1n4FQv0m"
   },
   "source": [
    "Data Loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tkmXIgAqsIk"
   },
   "outputs": [],
   "source": [
    "train_loader_nn = torch.utils.data.DataLoader(\n",
    "    dataset=traindata, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "val_loader_nn = torch.utils.data.DataLoader(\n",
    "    dataset=validate, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "test_loader_nn = torch.utils.data.DataLoader(\n",
    "    dataset=test, batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Df4qZFgRcB6"
   },
   "source": [
    "Training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5O_pSEt2qsIk",
    "outputId": "4f82cd48-8312-4686-9add-56c31153c558"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.8043\n",
      "Validataion accuracy is: 75.26572187776793 %\n",
      "Epoch [2/50], Loss: 0.6251\n",
      "Validataion accuracy is: 78.67581930912311 %\n",
      "Epoch [3/50], Loss: 0.6608\n",
      "Validataion accuracy is: 78.07794508414526 %\n",
      "Epoch [4/50], Loss: 0.5400\n",
      "Validataion accuracy is: 79.80513728963685 %\n",
      "Epoch [5/50], Loss: 0.6254\n",
      "Validataion accuracy is: 79.5837023914969 %\n",
      "Epoch [6/50], Loss: 0.6565\n",
      "Validataion accuracy is: 80.24800708591674 %\n",
      "Epoch [7/50], Loss: 0.4759\n",
      "Validataion accuracy is: 80.66873339238263 %\n",
      "Epoch [8/50], Loss: 0.7474\n",
      "Validataion accuracy is: 77.14791851195749 %\n",
      "Epoch [9/50], Loss: 0.4286\n",
      "Validataion accuracy is: 78.7422497785651 %\n",
      "Epoch [10/50], Loss: 0.6309\n",
      "Validataion accuracy is: 80.18157661647476 %\n",
      "Epoch [11/50], Loss: 0.4377\n",
      "Validataion accuracy is: 79.03011514614704 %\n",
      "Epoch [12/50], Loss: 0.4769\n",
      "Validataion accuracy is: 79.78299379982285 %\n",
      "Epoch [13/50], Loss: 0.5614\n",
      "Validataion accuracy is: 80.29229406554472 %\n",
      "Epoch [14/50], Loss: 0.4720\n",
      "Validataion accuracy is: 80.27015057573074 %\n",
      "Epoch [15/50], Loss: 0.6558\n",
      "Validataion accuracy is: 80.20372010628876 %\n",
      "Epoch [16/50], Loss: 0.4470\n",
      "Validataion accuracy is: 80.4251550044287 %\n",
      "Epoch [17/50], Loss: 0.4188\n",
      "Validataion accuracy is: 81.20017714791851 %\n",
      "Epoch [18/50], Loss: 0.4458\n",
      "Validataion accuracy is: 81.15589016829053 %\n",
      "Epoch [19/50], Loss: 0.4955\n",
      "Validataion accuracy is: 80.91231178033658 %\n",
      "Epoch [20/50], Loss: 0.5708\n",
      "Validataion accuracy is: 79.71656333038086 %\n",
      "Epoch [21/50], Loss: 0.6663\n",
      "Validataion accuracy is: 80.75730735163862 %\n",
      "Epoch [22/50], Loss: 0.5963\n",
      "Validataion accuracy is: 81.55447298494242 %\n",
      "Epoch [23/50], Loss: 0.3975\n",
      "Validataion accuracy is: 80.44729849424269 %\n",
      "Epoch [24/50], Loss: 0.4401\n",
      "Validataion accuracy is: 80.53587245349867 %\n",
      "Epoch [25/50], Loss: 0.4574\n",
      "Validataion accuracy is: 79.22940655447299 %\n",
      "Epoch [26/50], Loss: 0.5934\n",
      "Validataion accuracy is: 81.28875110717449 %\n",
      "Epoch [27/50], Loss: 0.5260\n",
      "Validataion accuracy is: 81.17803365810451 %\n",
      "Epoch [28/50], Loss: 0.3785\n",
      "Validataion accuracy is: 81.11160318866253 %\n",
      "Epoch [29/50], Loss: 0.5094\n",
      "Validataion accuracy is: 81.20017714791851 %\n",
      "Epoch [30/50], Loss: 0.4231\n",
      "Validataion accuracy is: 81.57661647475642 %\n",
      "Epoch [31/50], Loss: 0.4718\n",
      "Validataion accuracy is: 81.77590788308237 %\n",
      "Epoch [32/50], Loss: 0.5418\n",
      "Validataion accuracy is: 81.42161204605846 %\n",
      "Epoch [33/50], Loss: 0.2953\n",
      "Validataion accuracy is: 81.06731620903454 %\n",
      "Epoch [34/50], Loss: 0.2951\n",
      "Validataion accuracy is: 81.53232949512844 %\n",
      "Epoch [35/50], Loss: 0.3767\n",
      "Validataion accuracy is: 81.37732506643047 %\n",
      "Epoch [36/50], Loss: 0.4079\n",
      "Validataion accuracy is: 81.44375553587246 %\n",
      "Epoch [37/50], Loss: 0.3394\n",
      "Validataion accuracy is: 81.55447298494242 %\n",
      "Epoch [38/50], Loss: 0.5842\n",
      "Validataion accuracy is: 81.79805137289637 %\n",
      "Epoch [39/50], Loss: 0.5243\n",
      "Validataion accuracy is: 81.84233835252435 %\n",
      "Epoch [40/50], Loss: 0.4321\n",
      "Validataion accuracy is: 81.55447298494242 %\n",
      "Epoch [41/50], Loss: 0.3562\n",
      "Validataion accuracy is: 81.24446412754651 %\n",
      "Epoch [42/50], Loss: 0.5564\n",
      "Validataion accuracy is: 81.86448184233835 %\n",
      "Epoch [43/50], Loss: 0.4030\n",
      "Validataion accuracy is: 81.70947741364039 %\n",
      "Epoch [44/50], Loss: 0.5434\n",
      "Validataion accuracy is: 81.75376439326838 %\n",
      "Epoch [45/50], Loss: 0.4116\n",
      "Validataion accuracy is: 81.84233835252435 %\n",
      "Epoch [46/50], Loss: 0.4060\n",
      "Validataion accuracy is: 81.6873339238264 %\n",
      "Epoch [47/50], Loss: 0.3829\n",
      "Validataion accuracy is: 81.6430469441984 %\n",
      "Epoch [48/50], Loss: 0.4635\n",
      "Validataion accuracy is: 81.77590788308237 %\n",
      "Epoch [49/50], Loss: 0.5272\n",
      "Validataion accuracy is: 81.86448184233835 %\n",
      "Epoch [50/50], Loss: 0.5176\n",
      "Validataion accuracy is: 81.59875996457042 %\n"
     ]
    }
   ],
   "source": [
    "loss_ar = []\n",
    "lr = learning_rate\n",
    "total_train = 0\n",
    "correct_train = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (tokens, labels) in enumerate(train_loader_nn):\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(tokens)\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #####\n",
    "\n",
    "        if (i + 1) % 92 == 0:\n",
    "            print(\n",
    "                \"Epoch [{}/{}], Loss: {:.4f}\".format(epoch + 1, num_epochs, loss.item())\n",
    "            )\n",
    "            _, predicted_train = torch.max(outputs.data, 1)\n",
    "            loss_ar.append(loss.item())\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted_train == labels).sum().item()\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    # Code to update the lr\n",
    "    lr *= learning_rate_decay\n",
    "    update_lr(optimizer, lr)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for tokens, labels in val_loader_nn:\n",
    "            outputs = model(tokens)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            #############\n",
    "        print(\"Validataion accuracy is: {} %\".format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Co0W2ifGsMi2"
   },
   "outputs": [],
   "source": [
    "# Feel free to edit anything in this block\n",
    "\n",
    "# model = SomeModel(...)\n",
    "# model.train()\n",
    "\n",
    "# Optimizer\n",
    "# optimizer = None\n",
    "\n",
    "# Data Loaders\n",
    "# trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "# testloader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5w-7O5jsMi2"
   },
   "source": [
    "##  Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csbaYykoRiq3"
   },
   "source": [
    "Test function for model accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FP8GzDXBqsIl"
   },
   "outputs": [],
   "source": [
    "def test(test_loader_nn,model):\n",
    "  targets = []\n",
    "  pred = []\n",
    "  with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader_nn:\n",
    "\n",
    "      # images = images.to(device)\n",
    "\n",
    "      # labels = labels.to(device)\n",
    "      outputs = model(images)\n",
    "      _, predicted = torch.max(outputs.data, 1)\n",
    "      targets.append(labels)\n",
    "      pred.append(predicted)\n",
    "      total += labels.size(0)\n",
    "      correct += (predicted == labels).sum().item()\n",
    "\n",
    "  print('Accuracy of the network on the {} test images: {} %'.format(total, 100 * correct / total))\n",
    "  return test_loader_nn,predicted,targets,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6cEVWy7VqsIl",
    "outputId": "de94b4a1-344c-4111-b484-cf3c9c5e6cf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 82.71 %\n"
     ]
    }
   ],
   "source": [
    "_,_,target,pred = test(test_loader_nn,model)\n",
    "target = torch.cat(target)\n",
    "pred = torch.cat(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGZVwiKnRnHz"
   },
   "source": [
    "Plotting Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KWYgLHaRqsIl",
    "outputId": "a28f18af-9a7f-4098-92c4-ffce6eb7f435"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.52      0.58       294\n",
      "         1.0       1.00      0.99      1.00       345\n",
      "         2.0       0.99      1.00      0.99       467\n",
      "         3.0       0.76      1.00      0.86      1563\n",
      "         4.0       0.83      0.64      0.72      2528\n",
      "         5.0       0.00      0.00      0.00       335\n",
      "         6.0       0.96      1.00      0.98       428\n",
      "         7.0       0.79      0.96      0.86      2585\n",
      "         8.0       0.87      0.87      0.87       556\n",
      "         9.0       0.93      0.83      0.87       899\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.78      0.78      0.77     10000\n",
      "weighted avg       0.80      0.83      0.81     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(target, pred)\n",
    "rp = classification_report(target, pred)\n",
    "print(rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t4U6Cdk3qsIm",
    "outputId": "2e17d1f3-0e6c-4ef9-f2b3-c443f7ba6059"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 152    0    0    1  108    0    3   13    8    9]\n",
      " [   0  343    0    0    1    0    0    1    0    0]\n",
      " [   0    0  466    0    1    0    0    0    0    0]\n",
      " [   0    0    0 1559    4    0    0    0    0    0]\n",
      " [  60    1    4  498 1629    0   10  239   61   26]\n",
      " [   1    0    0    0    4    0    0  330    0    0]\n",
      " [   0    0    0    0    1    0  427    0    0    0]\n",
      " [   4    0    0    0   91    0    0 2469    1   20]\n",
      " [   3    0    0    2   63    0    3    0  484    1]\n",
      " [   6    0    0    0   66    0    0   81    4  742]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm,['Agent' 'Allaple' 'AutoIt' 'Basun' 'NothingFound' 'Patched' 'Swizzor'\n",
    " 'Texel' 'VB' 'Virut'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_GE1BQjsMi3"
   },
   "source": [
    "##  Save Model + Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "4Xvo--GIsMi3"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./model_bigram_vocab_10000\" + \".ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-UQbfCrsMi3"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLD6dur1sMi3"
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QRKxLsPsMi3"
   },
   "source": [
    "##  Summary: Main Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKxxp4x3qsIm"
   },
   "source": [
    "1. Loaded test and train data from the given links, it was done in 2 steps as work around for limited RAM availability.\n",
    "\n",
    "> i) Train data was loaded first, and it was further divided into train and validation data, it was shuffled to get even distribution among themselves before splitting.\n",
    "\n",
    "> ii) Test data was loaded.\n",
    "\n",
    "2. Vectorization is done similar to method of *CountVectorizer* (assiging the count values to the corresponding index of tokens derived) in the form of unigrams and bigrams.\n",
    "\n",
    "3. Since number of tokens is high, we experimented with multiple combinations(vocabulary size) of most common tokens and assigning all other tokens to unknown token. Eg: For bigrams it will check if bigram is available in the chosen tokens if not check for unigrams as final resort, if nothing is available we will assign it to unknown token.\n",
    "\n",
    "4. We stored checkpoints of data for every combination of grams (unigram,  bigram) and vocabulary size which were used in training the models.\n",
    "\n",
    "5. Trained a neural network with different hyperparameters and found the following setting ideal:\n",
    "\n",
    "    batch_size = 100\n",
    "\n",
    "    num_epochs = 50\n",
    "    \n",
    "    regularization= 0.001\n",
    "    \n",
    "    hidden_dim = [1000, 800]\n",
    "    \n",
    "    learning_rate = 2e-3\n",
    "    \n",
    "    learning_rate_decay = 0.95\n",
    "    \n",
    "    adam optimizer\n",
    "\n",
    "Input Representation   | Vocabulary size    |   Test accuracy\n",
    "-----------------------|--------------------|----------------\n",
    "unigram                | 10                 |75.51%\n",
    "unigram                | 100                |81.57 %\n",
    "bigram                 | 10                 |73.67 %\n",
    "bigram                 | 100                |76.7 %\n",
    "bigram                 | 1000               |82.02 %\n",
    "bigram                 | 5000               |82.37 %\n",
    "bigram                 | 7500               |82.59 %\n",
    "bigram                 | 10000              |82.71 %\n",
    "\n",
    "6. Finally we test the model with our 10000 samples dataset, and we got an accuracy of 82.71 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "dNKqJAoasMi4"
   },
   "source": [
    "##  Discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODnOBHqeqsIm"
   },
   "source": [
    "**Simplest approach:**\n",
    "\n",
    "We considered simplest approach as unigram with vocabulary size of 10, as we can see above in table, performance was not good since we are considering only little vocabulary size and lot of tokens are assigned to unknown token, making it useless for classification task.\n",
    "\n",
    "**Vectorized input representations:**\n",
    "\n",
    "We tried different representations by varying two important aspects of input which are *levels of syscalls* (leading to unigram and bigram) and *vocabulary size* (number of tokens to be considered). We can seen in our results that unigrams perform better for same vocabulary size when compared to bigrams, which may be due to the fact that extra level added for bigram is not helping much in categorization task and even making it worse since the level added is not generic to syscalls. This effect might be extrapolated to trigrams or higher order n-grams. But, this is not true if we increase vocabulary size because there is huge vocabulary available for bigrams when compared to unigrams. Hence, bigrams with higher vocabulary performs better than unigrams with low vocabulary.\n",
    "\n",
    "**Hard to detect malwares:**\n",
    "\n",
    "As we observed in the confusion matrix 'Agent' and 'Patched' malwares were performing poorly in the classification task. We may hypothesize that this is because unigrams and bigrams are not sufficient enough to capture the classification features for this type of malware classes.\n",
    "\n",
    "We can notice that malware 'Patched' is classified in most cases as 'Texel', this could happen because both classes are similar and the model is not able to find the characteristics that differenciate each categories, or because there is not data enough for class 5.\n",
    "\n",
    "We tried different architectures for our Neural Network, varying hyperparameters such as learning rate, epochs, amount of layers and nodes and regularization techniques. However, it was not possible to increase the validation accuracy. As we mentioned before, this could happen because we don't have data enough for the model to learn representation of each class.\n",
    "\n",
    "**Recommendation for Malware classification:**\n",
    "\n",
    "We can try out to include higher levels of syscalls(trigrams or higher order n-grams). We can also explore other methods of vectorization where we can include the context of syscalls not only their count which may be fed into Rnn's or transformers leading to better classification due to the sequence captured by the models.\n",
    "\n",
    "Aditionally, we can adjust the class distribution of a data set to make sure the dataset is balanced during training and let me model find the representations for each class."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2021_11_26_Task_03.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python394jvsc74a57bd07812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
